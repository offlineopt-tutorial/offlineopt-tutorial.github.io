[{"authors":null,"categories":null,"content":"","date":1607817600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1607817600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Aryan Deshwal","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Wowchemy\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://offlineopt-tutorial.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Aryan Deshwal","Âê≥ÊÅ©ÈÅî"],"categories":["Demo","ÊïôÁ®ã"],"content":"Overview  The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site The template can be modified and customised to suit your needs. It\u0026rsquo;s a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a no-code solution (write in Markdown and customize with YAML parameters) and having flexibility to later add even deeper personalization with HTML and CSS You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more    The template is mobile first with a responsive design to ensure that your site looks stunning on every device.  Get Started  üëâ Create a new site üìö Personalize your site üí¨ Chat with the Wowchemy community or Hugo community üê¶ Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy üí° Request a feature or report a bug for Wowchemy ‚¨ÜÔ∏è Updating Wowchemy? View the Update Guide and Release Notes  Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n‚ù§Ô∏è Click here to become a sponsor and help support Wowchemy\u0026rsquo;s future ‚ù§Ô∏è As a token of appreciation for sponsoring, you can unlock these awesome rewards and extra features ü¶Ñ‚ú®\nEcosystem  Hugo Academic CLI: Automatically import publications from BibTeX  Inspiration Check out the latest demo of what you\u0026rsquo;ll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\nFeatures  Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 34+ language packs including English, ‰∏≠Êñá, and Portugu√™s Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files.  Themes Wowchemy and its templates come with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://offlineopt-tutorial.github.io/post/getting-started/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Welcome üëã We know that first impressions are important, so we've populated your new site with some initial content to help you get familiar with everything in no time.","tags":["Academic","ÂºÄÊ∫ê"],"title":"Welcome to Wowchemy, the website builder for Hugo","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  **Two**  Three   A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://offlineopt-tutorial.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"e8f8d235e8e7f2efd912bfe865363fc3","permalink":"https://offlineopt-tutorial.github.io/project/example/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/example/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Example Project","type":"project"},{"authors":["Aryan Deshwal","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including code, math, and images.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"ff6a19061a984819d30c916886db56ef","permalink":"https://offlineopt-tutorial.github.io/publication/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/example/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"An example conference paper","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://offlineopt-tutorial.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"},{"authors":null,"categories":null,"content":"Slides Schedule First part: one hour 45 mins  Overview of the BO Framework, GPs, advances in GPs and acquisition functions, and BoTorch demo Bayesian Optimization over Discrete/Hybrid Spaces Multi-fidelity Bayesian Optimization  Break: 30 Mins Second part: one hour 45 mins  High-Dimensional BO and BoTorch demo Multi-Objective BO and BoTorch demo Summary and Outstanding Challenges in BO  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0d09127d49a82b0e72d63da5772d010e","permalink":"https://offlineopt-tutorial.github.io/syllabus/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/syllabus/","section":"","summary":"Slides Schedule First part: one hour 45 mins  Overview of the BO Framework, GPs, advances in GPs and acquisition functions, and BoTorch demo Bayesian Optimization over Discrete/Hybrid Spaces Multi-fidelity Bayesian Optimization  Break: 30 Mins Second part: one hour 45 mins  High-Dimensional BO and BoTorch demo Multi-Objective BO and BoTorch demo Summary and Outstanding Challenges in BO  ","tags":null,"title":"","type":"page"},{"authors":null,"categories":null,"content":"General introduction and survey  Garnett, R. (2022). Bayesian Optimization. Cambridge University Press. Link Shahriari, B., Swersky, K., Wang, Z., Adams, R. P., \u0026amp; De Freitas, N. (2015). Taking the human out of the loop: A review of Bayesian optimization. Proceedings of the IEEE, 104(1), 148-175. Link Frazier, P. I. (2018). A tutorial on Bayesian optimization. arXiv preprint arXiv:1807.02811. Link Greenhill, S., Rana, S., Gupta, S., Vellanki, P., \u0026amp; Venkatesh, S. (2020). Bayesian optimization for adaptive experimental design: A review. IEEE access, 8, 13937-13948. Link Brochu, E., Cora, V. M., \u0026amp; De Freitas, N. (2010). A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning. arXiv preprint arXiv:1012.2599. Link  Gaussian Processes  Williams, C. K., \u0026amp; Rasmussen, C. E. (2006). Gaussian processes for machine learning (Vol. 2, No. 3, p. 4). Cambridge, MA: MIT press. Link Leibfried, F., Dutordoir, V., John, S. T., \u0026amp; Durrande, N. (2020). A tutorial on sparse Gaussian processes and variational inference. arXiv preprint arXiv:2012.13962. Link  Acquisition functions and their optimization  Moƒçkus, J. (1975). On Bayesian methods for seeking the extremum. In Optimization techniques IFIP technical conference (pp. 400-404). Springer, Berlin, Heidelberg. Srinivas, N., Krause, A., Kakade, S. M., \u0026amp; Seeger, M. (2009). Gaussian process optimization in the bandit setting: No regret and experimental design. arXiv preprint arXiv:0912.3995. Frazier, P., Powell, W., \u0026amp; Dayanik, S. (2009). The knowledge-gradient policy for correlated normal beliefs. INFORMS journal on Computing, 21(4), 599-613. Hennig, P., \u0026amp; Schuler, C. J. Entropy search for information-efficient global optimization. Journal of Machine Learning Research (JMLR), 13, 1809‚Äì1837, 2012. Hernandez-Lobato, J. M., Hoffman, M. W., \u0026amp; Ghahramani, Z. Predictive entropy search for efficient global optimization of black-box functions. Advances in Neural Information Processing Systems (NIPS), pp. 918‚Äì926, 2014. Wang, Z., \u0026amp; Jegelka, S. (2017, July). Max-value entropy search for efficient Bayesian optimization. In International Conference on Machine Learning (pp. 3627-3635). PMLR. Jiang, S., Jiang, D., Balandat, M., Karrer, B., Gardner, J., \u0026amp; Garnett, R. (2020). Efficient nonmyopic bayesian optimization via one-shot multi-step trees. Advances in Neural Information Processing Systems, 33, 18039-18049. Lam, R., Willcox, K., \u0026amp; Wolpert, D. H. (2016). Bayesian optimization with a finite budget: An approximate dynamic programming approach. Advances in Neural Information Processing Systems, 29. Gonz√°lez, J., Osborne, M., \u0026amp; Lawrence, N. (2016, May). GLASSES: Relieving the myopia of Bayesian optimisation. In Artificial Intelligence and Statistics (pp. 790-799). PMLR. Balandat, M., Karrer, B., Jiang, D., Daulton, S., Letham, B., Wilson, A. G., \u0026amp; Bakshy, E. (2020). BoTorch: a framework for efficient Monte-Carlo Bayesian optimization. Advances in neural information processing systems, 33, 21524-21538. Kim, J., \u0026amp; Choi, S. (2020, September). On local optimizers of acquisition functions in bayesian optimization. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases (pp. 675-690). Springer, Cham. Wilson, J., Hutter, F., \u0026amp; Deisenroth, M. (2018). Maximizing acquisition functions for Bayesian optimization. Advances in neural information processing systems, 31. Grosnit, A., Cowen-Rivers, A. I., Tutunov, R., Griffiths, R. R., Wang, J., \u0026amp; Bou-Ammar, H. (2021). Are we forgetting about compositional optimisers in bayesian optimisation?. Journal of Machine Learning Research, 22(160), 1-78.  Multi-fidelity Bayesian optimization  Huang, D., Allen, T. T., Notz, W. I., \u0026amp; Miller, R. A. (2006). Sequential kriging optimization using multiple-fidelity evaluations. Structural and Multidisciplinary Optimization, 32(5), 369-382. Swersky, K., Snoek, J., \u0026amp; Adams, R. P. (2013). Multi-task bayesian optimization. Advances in neural information processing systems, 26. Kandasamy, K., Dasarathy, G., Schneider, J., \u0026amp; P√≥czos, B. (2017, July). Multi-fidelity bayesian optimisation with continuous approximations. In International Conference on Machine Learning (pp. 1799-1808). PMLR. Klein, A., Falkner, S., Bartels, S., Hennig, P., \u0026amp; Hutter, F. (2017, April). Fast bayesian optimization of machine learning hyperparameters on large datasets. In Artificial intelligence and statistics (pp. 528-536). PMLR. Song, J., Chen, Y., \u0026amp; Yue, Y. (2019, April). A general framework for multi-fidelity bayesian optimization with gaussian processes. In The 22nd International Conference on Artificial Intelligence and Statistics (pp. 3158-3167). PMLR. Wu, J., Toscano-Palmerin, S., Frazier, P. I., \u0026amp; Wilson, A. G. (2020, August). Practical multi-fidelity Bayesian optimization for hyperparameter tuning. In Uncertainty in Artificial Intelligence (pp. 788-798). PMLR. Takeno, S., Fukuoka, H., Tsukada, Y., Koyama, T., Shiga, M., Takeuchi, I., \u0026amp; Karasuyama, M. (2020, November). Multi-fidelity Bayesian optimization with max-value entropy search and its parallelization. In International Conference on Machine Learning (pp. 9334-9345). PMLR. Zhang, Y., Dai, Z., \u0026amp; Low, B. K. H. (2020, August). Bayesian optimization with binary auxiliary information. In Uncertainty in Artificial Intelligence (pp. 1222-1232). PMLR. Li, S., Xing, W., Kirby, R., \u0026amp; Zhe, S. (2020). Multi-fidelity Bayesian optimization via deep neural networks. Advances in Neural Information Processing Systems, 33, 8521-8531.  Combinatorial Bayesian optimization  Deshwal, A., Belakaria, S., Doppa, J. R., \u0026amp; Fern, A. (2020). Optimizing discrete spaces via expensive evaluations: A learning to search framework. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 34, No. 04, pp. 3773-3780). Deshwal, A., Belakaria, S., \u0026amp; Doppa, J. R. (2021). Mercer features for efficient combinatorial Bayesian optimization. In Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI) (pp. 7210-7218). Deshwal, A., \u0026amp; Doppa, J. (2021). Combining Latent Space and Structured Kernels for Bayesian Optimization over Combinatorial Spaces. Advances in Neural Information Processing Systems, 34. Deshwal, A., Belakaria, S., \u0026amp; Doppa, J. R. (2020). Scalable combinatorial Bayesian optimization with tractable statistical models. arXiv preprint arXiv:2008.08177. Baptista, R., \u0026amp; Poloczek, M. (2018, July). Bayesian optimization of combinatorial structures. In International Conference on Machine Learning (pp. 462-471). PMLR. Garrido-Merch√°n, E. C., \u0026amp; Hern√°ndez-Lobato, D. (2020). Dealing with categorical and integer-valued variables in bayesian optimization with gaussian processes. Neurocomputing, 380, 20-35. Oh, C., Tomczak, J., Gavves, E., \u0026amp; Welling, M. (2019). Combinatorial bayesian optimization using the graph cartesian product. Advances in Neural Information Processing Systems, 32. Swersky, K., Rubanova, Y., Dohan, D., \u0026amp; Murphy, K. (2020). Amortized bayesian optimization over discrete spaces. In Conference on Uncertainty in Artificial Intelligence (pp. 769-778). PMLR. Moss, H., Leslie, D., Beck, D., Gonzalez, J., \u0026amp; Rayson, P. (2020). Boss: Bayesian optimization over string spaces. Advances in neural information processing systems, 33, 15476-15486. Buathong, P., Ginsbourger, D., \u0026amp; Krityakierne, T. (2020). Kernels over sets of finite sets using RKHS embeddings, with application to Bayesian (combinatorial) optimization. In International Conference on Artificial Intelligence and Statistics (pp. 2731-2741). PMLR. Dadkhahi, H., Shanmugam, K., Rios, J., Das, P., Hoffman, S. C., Loeffler, T. D., \u0026amp; Sankaranarayanan, S. (2020, August). Combinatorial black-box optimization with expert advice. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \u0026amp; Data Mining (pp. 1918-1927). Kim, J., McCourt, M., You, T., Kim, S., \u0026amp; Choi, S. (2021). Bayesian optimization with approximate set kernels. Machine Learning, 110(5), 857-879. Griffiths, R. R., \u0026amp; Hern√°ndez-Lobato, J. M. (2020). Constrained Bayesian optimization for automatic chemical design using variational autoencoders. Chemical science, 11(2), 577-586. Maus, N., Jones, H. T., Moore, J. S., Kusner, M. J., Bradshaw, J., \u0026amp; Gardner, J. R. (2022). Local Latent Space Bayesian Optimization over Structured Inputs, Neural Information Processing Systems (NeurIPS) 2022.  Causal Bayesian Optimization  Aglietti V., Dhir N., Gonz√°lez J. and Damoulas T. (2021). Dynamic Causal Bayesian Optimization, Neural Information Processing Systems (NeurIPS) 2021. Aglietti V., Damoulas T., Alvarez A.M., \u0026amp; Gonz√°lez J. (2020). Multi-task Causal Learning with Gaussian Processes, Neural Information Processing Systems (NeurIPS) 2020. Aglietti V., Lu X., Paleyes A., \u0026amp; Gonz√°lez J. (2020). Causal Bayesian Optimization, International Conference on Artificial Intelligence and Statistics (AISTATS) 2020. Aglietti V., Bonilla E., Damoulas T. \u0026amp; Cripps S. (2019). Structured Variational Inference in Continuous Cox Process Models, Neural Information Processing Systems (NeurIPS) 2019. Aglietti V., Damoulas T. \u0026amp; Bonilla E. (2019). Efficient Inference in Multi-task Cox Process Models, International Conference on Artificial Intelligence and Statistics (AISTATS) 2019.  BO over hybrid spaces  Deshwal, A., Belakaria, S., \u0026amp; Doppa, J. R. (2021). Bayesian optimization over hybrid spaces. In International Conference on Machine Learning (pp. 2632-2643). PMLR. Daxberger, E., Makarova, A., Turchetta, M., \u0026amp; Krause, A. (2019). Mixed-variable bayesian optimization. arXiv preprint arXiv:1907.01329. Oh, C., Gavves, E., \u0026amp; Welling, M. (2021). Mixed variable Bayesian optimization with frequency modulated kernels. In Uncertainty in Artificial Intelligence (pp. 950-960). PMLR. Ru, B., Alvi, A., Nguyen, V., Osborne, M. A., \u0026amp; Roberts, S. (2020, November). Bayesian optimisation over multiple continuous and categorical inputs. In International Conference on Machine Learning (pp. 8276-8285). PMLR.  High-dimensional Bayesian optimization  Eriksson, D., Pearce, M., Gardner, J., Turner, R. D., \u0026amp; Poloczek, M. (2019). Scalable global optimization via local bayesian optimization. Advances in Neural Information Processing Systems, 32. Li, C., Gupta, S., Rana, S., Nguyen, V., Venkatesh, S., \u0026amp; Shilton, A. (2017). High Dimensional Bayesian Optimization Using Dropout. Proceedings of the 26th International Joint Conference on Artificial Intelligence, 2096‚Äì2102. Melbourne, Australia: AAAI Press. Mutny, M., \u0026amp; Krause, A. (2018). Efficient high dimensional bayesian optimization with additivity and quadrature fourier features. Advances in Neural Information Processing Systems, 31. Wang, Z., Gehring, C., Kohli, P., \u0026amp; Jegelka, S. (2018, March). Batched large-scale Bayesian optimization in high-dimensional spaces. In International Conference on Artificial Intelligence and Statistics (pp. 745-754). PMLR. Oh, C., Gavves, E., \u0026amp; Welling, M. (2018, July). BOCK: Bayesian optimization with cylindrical kernels. In International Conference on Machine Learning (pp. 3868-3877). PMLR. Rolland, P., Scarlett, J., Bogunovic, I., \u0026amp; Cevher, V. (2018, March). High-dimensional Bayesian optimization via additive models with overlapping groups. In International conference on artificial intelligence and statistics (pp. 298-307). PMLR. Li, C. L., Kandasamy, K., P√≥czos, B., \u0026amp; Schneider, J. (2016, May). High dimensional Bayesian optimization via restricted projection pursuit models. In Artificial Intelligence and Statistics (pp. 884-892). PMLR. Zhang, M., Li, H., \u0026amp; Su, S. (2019). High dimensional Bayesian optimization via supervised dimension reduction. arXiv preprint arXiv:1907.08953. Hoang, T. N., Hoang, Q. M., Ouyang, R., \u0026amp; Low, K. H. (2018, April). Decentralized high-dimensional Bayesian optimization with factor graphs. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 32, No. 1). Maddox, W. J., Balandat, M., Wilson, A. G., \u0026amp; Bakshy, E. (2021). Bayesian optimization with high-dimensional outputs. Advances in Neural Information Processing Systems, 34. Wan, X., Nguyen, V., Ha, H., Ru, B., Lu, C., \u0026amp; Osborne, M. A. (2021). Think global and act local: Bayesian optimisation over high-dimensional categorical and mixed search spaces. arXiv preprint arXiv:2102.07188. Eriksson, D., \u0026amp; Jankowiak, M. (2021). High-dimensional Bayesian optimization with sparse axis-aligned subspaces. In Uncertainty in Artificial Intelligence (pp. 493-503). PMLR.  Batch Bayesian Optimization  Wu, J., \u0026amp; Frazier, P. (2016). The parallel knowledge gradient method for batch Bayesian optimization. Advances in neural information processing systems, 29. Ginsbourger, D., Riche, R. L., \u0026amp; Carraro, L. (2010). Kriging is well-suited to parallelize optimization. In Computational intelligence in expensive optimization problems (pp. 131-162). Springer, Berlin, Heidelberg. Gonz√°lez, J., Dai, Z., Hennig, P., \u0026amp; Lawrence, N. (2016, May). Batch Bayesian optimization via local penalization. In Artificial intelligence and statistics (pp. 648-657). PMLR. Nguyen, V., Rana, S., Gupta, S. K., Li, C., \u0026amp; Venkatesh, S. (2016, December). Budgeted batch Bayesian optimization. In 2016 IEEE 16th International Conference on Data Mining (ICDM) (pp. 1107-1112). IEEE. Wang, Z., Hutter, F., Zoghi, M., Matheson, D., \u0026amp; de Feitas, N. (2016). Bayesian optimization in a billion dimensions via random embeddings. Journal of Artificial Intelligence Research, 55, 361-387. Azimi, J., Fern, A., \u0026amp; Fern, X. (2010). Batch bayesian optimization via simulation matching. Advances in Neural Information Processing Systems, 23. Azimi, J., Jalali, A., \u0026amp; Fern, X. (2012). Hybrid batch Bayesian optimization. arXiv preprint arXiv:1202.5597. Gong, C., Peng, J., \u0026amp; Liu, Q. (2019, May). Quantile stein variational gradient descent for batch Bayesian optimization. In International Conference on Machine Learning (pp. 2347-2356). PMLR. Kandasamy, K., Krishnamurthy, A., Schneider, J., \u0026amp; P√≥czos, B. (2018, March). Parallelised Bayesian optimisation via Thompson sampling. In International Conference on Artificial Intelligence and Statistics (pp. 133-142). PMLR.  Constrained Bayesian Optimization  Gardner, J. R., Kusner, M. J., Xu, Z. E., Weinberger, K. Q., \u0026amp; Cunningham, J. P. (2014, June). Bayesian Optimization with Inequality Constraints. In ICML (Vol. 2014, pp. 937-945). Gelbart, Michael A., Jasper Snoek, and Ryan P. Adams. ‚ÄúBayesian optimization with unknown constraints.‚Äù arXiv preprint arXiv:1403.5607 (2014). Hern√°ndez-Lobato, Jos√© Miguel, et al. ‚ÄúPredictive entropy search for bayesian optimization with unknown constraints.‚Äù International conference on machine learning. PMLR, 2015. Perrone, Valerio, et al. ‚ÄúConstrained Bayesian optimization with max-value entropy search.‚Äù arXiv preprint arXiv:1910.07003 (2019). Letham, Benjamin, et al. ‚ÄúConstrained Bayesian optimization with noisy experiments.‚Äù Bayesian Analysis 14.2 (2019): 495-519. Eriksson, David, and Matthias Poloczek. ‚ÄúScalable constrained bayesian optimization.‚Äù International Conference on Artificial Intelligence and Statistics. PMLR, 2021. Chen, Wenjie, Shengcai Liu, and Ke Tang. ‚ÄúA new knowledge gradient-based method for constrained bayesian optimization.‚Äù arXiv preprint arXiv:2101.08743 (2021). Takeno, S., Tamura, T., Shitara, K., \u0026amp; Karasuyama, M. (2021). Sequential-and Parallel-Constrained Max-value Entropy Search via Information Lower Bound. arXiv preprint arXiv:2102.09788.  Multi-Objective Bayesian Optimization  Belakaria, S., Deshwal, A., \u0026amp; Doppa, J. R. ‚ÄúMax-value entropy search for multi-objective bayesian optimization.‚Äù Advances in neural information processing systems 32 (2019). Belakaria, S., Deshwal, A., Jayakodi, N. K., \u0026amp; Doppa, J. R. (2020, April). Uncertainty-aware search framework for multi-objective Bayesian optimization. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 34, No. 06, pp. 10044-10052). Belakaria, S., Deshwal, A., \u0026amp; Doppa, J. R. (2020, April). Multi-fidelity multi-objective Bayesian optimization: An output space entropy search approach. In Proceedings of the AAAI Conference on artificial intelligence (Vol. 34, No. 06, pp. 10035-10043). Belakaria, S., Deshwal, A., \u0026amp; Doppa, J. R. (2021). Output space entropy search framework for multi-objective bayesian optimization. Journal of Artificial Intelligence Research, 72, 667-715. Knowles, J. (2006). ParEGO: A hybrid algorithm with on-line landscape approximation for expensive multiobjective optimization problems. IEEE Transactions on Evolutionary Computation, 10(1), 50-66. Emmerich, M., \u0026amp; Klinkenberg, J. W. (2008). The computation of the expected improvement in dominated hypervolume of Pareto front approximations. Rapport technique, Leiden University, 34, 7-3. Zuluaga, M., Sergent, G., Krause, A., \u0026amp; P√ºschel, M. (2013, February). Active learning for multi-objective optimization. In International Conference on Machine Learning (pp. 462-470). PMLR. Picheny, V. (2015). Multiobjective optimization using Gaussian process emulators via stepwise uncertainty reduction. Statistics and Computing, 25(6), 1265-1280. Hern√°ndez-Lobato, D., Hernandez-Lobato, J., Shah, A., \u0026amp; Adams, R. (2016, June). Predictive entropy search for multi-objective bayesian optimization. In International conference on machine learning (pp. 1492-1501). PMLR. Shah, A., \u0026amp; Ghahramani, Z. (2016, June). Pareto frontier learning with expensive correlated objectives. In International conference on machine learning (pp. 1919-1927). PMLR. Paria, B., Kandasamy, K., \u0026amp; P√≥czos, B. (2020, August). A flexible framework for multi-objective bayesian optimization using random scalarizations. In Uncertainty in Artificial Intelligence (pp. 766-776). PMLR. Zhang, R., Golovin, D.. (2020). Random Hypervolume Scalarizations for Provable Multi-Objective Black Box Optimization. Proceedings of the 37th International Conference on Machine Learning, PMLR Daulton, S., Balandat, M., \u0026amp; Bakshy, E. (2020). Differentiable expected hypervolume improvement for parallel multi-objective Bayesian optimization. Advances in Neural Information Processing Systems, 33, 9851-9864. Suzuki, S., Takeno, S., Tamura, T., Shitara, K., \u0026amp; Karasuyama, M. (2020, November). Multi-objective Bayesian optimization using Pareto-frontier entropy. In International Conference on Machine Learning (pp. 9279-9288). PMLR. Konakovic Lukovic, M., Tian, Y., \u0026amp; Matusik, W. (2020). Diversity-guided multi-objective bayesian optimization with batch evaluations. Advances in Neural Information Processing Systems, 33, 17708-17720. Daulton, S., Balandat, M., \u0026amp; Bakshy, E. (2021). Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement. Advances in Neural Information Processing Systems, 34. Garrido-Merch√°n, Eduardo C., and Daniel Hern√°ndez-Lobato. ‚ÄúPredictive entropy search for multi-objective bayesian optimization with constraints.‚Äù Neurocomputing 361 (2019): 50-68. Fern√°ndez-S√°nchez, D., Garrido-Merch√°n, E. C., \u0026amp; Hern√°ndez-Lobato, D. (2020). Improved Max-value Entropy Search for Multi-objective Bayesian Optimization with Constraints. arXiv preprint arXiv:2011.01150. Chowdhury, S. R., \u0026amp; Gopalan, A. (2021, March). No-regret algorithms for multi-task bayesian optimization. In International Conference on Artificial Intelligence and Statistics (pp. 1873-1881). PMLR.  BO over conditional/tree-structured search space  Jenatton, R., Archambeau, C., Gonz√°lez, J., \u0026amp; Seeger, M. (2017, July). Bayesian optimization with tree-structured dependencies. In International Conference on Machine Learning (pp. 1655-1664). PMLR. Swersky, K., Duvenaud, D., Snoek, J., Hutter, F., \u0026amp; Osborne, M. A. (2014). Raiders of the lost architecture: Kernels for Bayesian optimization in conditional parameter spaces. arXiv preprint arXiv:1409.4011. Ma, X., \u0026amp; Blaschko, M. (2020, June). Additive tree-structured covariance function for conditional parameter spaces in Bayesian optimization. In International Conference on Artificial Intelligence and Statistics (pp. 1015-1025). PMLR.  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"fb2468a3ad64aa7401d292e2347ca96e","permalink":"https://offlineopt-tutorial.github.io/references/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/references/","section":"","summary":"General introduction and survey  Garnett, R. (2022). Bayesian Optimization. Cambridge University Press. Link Shahriari, B., Swersky, K., Wang, Z., Adams, R. P., \u0026amp; De Freitas, N. (2015). Taking the human out of the loop: A review of Bayesian optimization.","tags":null,"title":"List of references","type":"page"}]